---
title: "Data Exploration Handout"
author: "Coleridge"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: 
    margin_references: true
    toc: true
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
link-citations: yes
---

```{r setup, include=FALSE}
library(tufte)
# invalidate cache when the tufte version changes
library(yaml)
library(tidyverse)
library(magrittr)
setwd("/Users/sophierand/Desktop/ada-tdc-2020")
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)

code_snips_file <-"/Users/sophierand/Desktop/ada-tdc-2020/code_snips.yml"
code_snips_list <- yaml::read_yaml(code_snips_file, fileEncoding = "UTF-8")

code_snips <- as.data.frame(matrix(unlist(code_snips_list), nrow=length(code_snips_list), byrow=TRUE))
colnames(code_snips) <- names(code_snips_list[[1]])
```

# Introduction

The goal of the Data Exploration lesson is to provide a framework for describing the relationship between the labor market faced by TANF recipients and their earnings and employment outcomes. Use the analysis to shed light on the current crisis.

We will answer the following questions:

1.  What are the earnings and employment outcomes of TANF recipients?  
1.  What are the characteristics of employers likely to hire TANF recipients?  

_Policy Relevance: The TANF program “is designed to help needy families achieve self-sufficiency.” State agencies administering this federal program have an interest in understanding how TANF participation can support long-term, stable employment to achieve these goals. Administrative data on TANF participation joined with administrative data on earnings and employers can be used to describe the labor market outcomes of TANF recipients._

# Lesson Structure

The lesson is given over the course of two days - Concepts of Data Exploration and Applications of Data Exploration. 

```{marginfigure, echo=TRUE}
**Materials**:  
1. Data Exploration Video Lecture  
2. `Data Exploration.ipynb`  
```

This handout mirrors the content in the Data Exploration notebook lesson which you can access only in the Administrative Data Research Facility (ADRF). **There is no sensitive data anywhere in this document.** It is a handy reference to use as you step through the lesson in the ADRF, and to refer back to in the future.

Each section has:   

- **Guiding Questions**, summarized at the top of the section and dispersed throughout the document in <span style="color:green; ">green</span>.
- **Ask Yourself Questions**, quick, bite-sized questions for your sake as a brain-check - to make sure we're all on the same page. in <span style="color:blue; ">blue</span>.
- **Checkpoints**,  which are mini-exercises for you to complete, to be reviewed during "in-class" time. They are included in each section in <span style="color:red; ">red</span>.

`r margin_note('these come from the syllabus')`
# Learning Objectives and Outcomes

**Concepts of Data Exploration**
1.   Become familiar with common measures of employment outcomes.
1.   Begin to think about which measures are most important to their home state’s pilot project.
1.   Be introduced to specifications of the cohorts.
**Applications of Data Exploration**
1.  Become comfortable querying the database with SQL queries in R.
1.  Become comfortable using the main tables in TANF and UI data.
1.  Gain skills in creating basic descriptives of the datasets, aggregating data frames.
1.  Learn to calculate employment outcome metrics (given a pre-defined cohort) which were discussed in **Concepts of Data Exploration**.



<!-- ## Day 2, Concepts of Data Exploration -->

<!-- `r margin_note('this was all taken from the master syllabus. remove?')` -->

<!-- At the end of this section, participants will have learned of common metrics for employment outcomes and will understand the analytical frame and questions to consider when developing an analysis using such metrics. The lesson will range from covering basic statistics to developing an analytical frame for creating employment metrics. This material will lay the groundwork for the hands-on data exploration tasks covered in Day 3. -->

<!-- _Policy Relevance: Understanding employment trajectories of TANF recipients is the primary focus of this course, and through a lecture and discussion session, participants will understand the primary metrics used to measure employment outcomes.  They will be exposed to the questions that frame the analytical task and yield decisions around which metrics to use. Participants will consider, for example, whether individuals had other TANF experience post-“exit”; whether to look at annual earnings, earnings from dominant employers or all employers, etc. _ -->


<!-- **Learning Objectives:**       -->

<!-- 1.   Become familiar with common measures of employment outcomes.     -->
<!-- 1.   Begin to think about which measures are most important to their home state’s pilot project.   -->
<!-- 1.   Be introduced to specifications of the cohort that they will be working with on Day 3.    -->
<!-- 1.   Be prepared for the hands-on Data Exploration notebook for tomorrow.    -->

<!-- ## Day 3, Applications of Data Exploration -->

<!-- We will apply lessons learned from yesterday’s lecture and begin working with the data in earnest. Participants will learn to query, filter and aggregate the data and create basic descriptive statistics of employment and earnings. Using pre-written code developed to create a cohort of TANF exiters, participants will calculate employment and earnings metrics for the cohort post-exit.  They will also describe the hiring patterns of firms.  -->

<!-- _Policy Relevance: Participants will learn how to generate descriptive statistics on TANF and UI Wage data and calculate employment outcome metrics (e.g. “full quarter employment”)._ -->

<!-- **Learning Objectives:**   -->

<!-- 1.  Become comfortable querying the database with SQL queries in R.    -->
<!-- 1.  Become comfortable using the main tables in TANF and UI data.    -->
<!-- 1.  Gain skills in creating basic descriptives of the datasets, aggregating data frames.   -->
<!-- 1.  Learn to calculate employment outcome metrics (given a pre-defined cohort) which were discussed on Day 2.    -->


# Lesson Content
`r margin_note('data_exploration.ipynb')`

## R Setup
Load libraries   
`library(tidyverse)`  

```{marginfigure, echo=TRUE}
It is good practice to put the library name before the function, e.g. `DBI::dbGetQuery(con,query)`  in case the function you are using exists in multiple libraries. However if you're confident that the function you want to use exists in only one of the libraries loaded in your environment, you can skip it.
```

Calling functions from libraries   
`tidyverse::mutate()`  

Getting help on a library or function     
`?strptime`
`?tidyverse`

## Loading Data into R/Jupyter

Establish connection with `DBI` and `RPostgreSQL` libraries 

```yaml
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv
              ,dbname = "postgresql://stuffed.adrf.info/appliedda")
              
              
```

We will use this database connection `con` throughout this lesson. Then we create our first SQL query.

```yaml
query <- "SELECT * 
FROM in_fssa.person_month
LIMIT 20;"

query
```

Queries are run with the function `dbGetQuery` from the `DBI` library. The function expects 2 inoputs - the database connection, `con`, and the `query`.

```yaml
df <- dbGetQuery(con,query)
```


## What's in the database?

```{marginfigure, echo=TRUE}
Every SQL database has a metadata schema called `information_schema`
```
We learn more about what is in the database by inspecting the results of queries  `information_schema`.  Here, we  introduce the `head(df)` function which will print out the first 6 rows of the dataframe `df`.

```yaml
df <- dbGetQuery(con, "SELECT * FROM information_schema.schemata")

head(df)
```

Look at metadata on the columns in tables in the database.

```yaml
query <- "SELECT *
FROM information_schema.columns limit 10;"

dbGetQuery(con,query)
```



```{marginfigure, echo=TRUE}
**SCHEMAS**  
`ada_tdc_2020` - Cohort data. We will primarily query from this schema.    
`in_dwd`- Indiana UI Wage Record data      
`in_fssa` - Indiana TANF claims      
```
Query the schemas we will be using to see what tables they contain. We use the SQL commands `WHERE` and `IN` to filter to just look at our schemas.

```yaml
schema_query <- "SELECT DISTINCT 
table_schema,table_name
FROM information_schema.tables
WHERE table_schema  IN ('in_dwd', 'in_fssa', ;ada_tdc_2020')
limit 10;"

dbGetQuery(con,schema_query)

```

``` {marginfigure, echo = TRUE}
Plaeholders are denoted by `%s` if the expected replacement value is a string; `%d` if the expected replacement value is an integer; run `?sprintf` for more replacement values.
```
We will now _parameterize_ the query we just ran, using a string manipulation function called `sprintf`, which takes a string with placeholders, and their replacement value(s). A query that is parameterized is more flexible in that you can re-use queries and plug in new parameters (usually in the `FROM` or `WHERE` clause) without rewriting the query. This is useful for us in 2 ways: first, because we want to look at employment measures at different time points after exit from the TANF program; and second, because we want to compare these measures across different cohorts.

```{marginfigure, echo=TRUE}
First we establish which variables we will want to swap out - here, `schema` and `tbl`.


Then, we write a `base_query` with placeholders (denoted by `%s`) that indicate to the `sprintf` function where the replacement values go.


Finally, we use the `sprintf` function, a string manipulation, to tie it all together.
```

```yaml
schema <-"in_fssa"
tbl <- "person_month"

base_query <- "SELECT * 
FROM information_schema.columns
WHERE table_schema = '%s' AND table_name = '%s'"

query <- sprintf(base_query, schema,tbl)

dbGetQuery(con,query)
```

Now let's start looking at the data we'll be using for this class. Take a look at what's in the `in_fssa` monthly person-level TANF claims. Soon, we will look at tables of pre-defined cohorts, whcih were derived from this `person_month` table. 

```yaml
query <- "SELECT *
FROM in_fssa.person_month
limit 20;"

in_df <- dbGetQuery(con,query)

head(in_df)
```

## Individual
### Summary Statistics: TANF

**Guiding Questions:**  
For individuals who had a spell ending in 2016 Q4, we want to know:    

1.  What is the distribution of spell lengths amongst individuals in our cohort?
1.  What is the spell length at the 25th percentile?   
1.  What are the spell lengths at the 10th, 25th, 50th, and 75th percentiles?

```{marginfigure echo = TRUE}
See the [table_creation notebook](/Users/sophierand/Google Drive/tdc_handouts/table_creation_handout.html) for more on the cohorts.
```


**Tables:**
These calculations rely on `ada_tdc_2020.tanf_<year>q<quarter>` which contain data on the TANF spell which ended in the quarter specified in the cohort name. 

First, a quick look at the 2016 Q4 cohort. This is a cohort of individuals who were primary recipients of TANF and had a spell ending in the fourth quarter of 2016. 

```yaml
`r code_snips$code[code_snips$title=="tanf_cohort_preview"]`

```
<span style="color:blue;font-weight: bold; font-style: italic;">_**Ask Yourself: **_</span> What is the difference in the unit of analysis between the TANF claims in `in_fssa.person_month` and the spells in `ada_tdc_2020.tanf_2016q4`? Inspect the outputs of `in_df` and `cohort_df`.

_Answer:_ `in_fssa.person_month` has monthly TANF transactions (disbursement of benefits) and the unit of analysis is `person-month` while `ada_tdc_2020.tanf_2016q4` has data on the most recent spell  (the spell that 'qualified' the individual to be in the cohort).


<span style="color:blue;font-weight: bold; font-style: italic;">_**Ask Yourself: **_</span>  Which of the following are true, where n_ssn_tanf = # persons in `in_fssa`?

1. $$num_{ssn,tanf} > num_{ssn,cohort}$$  
1. $$num_{ssn,tanf} < num_{ssn,cohort}$$  
1. $$num_{ssn,cohort} = num_{rows,cohort}$$  
1. $$num_{ssn,cohort} \leq num_{rows,cohort}$$  


_Answer:_ 1, 2


```{marginfigure echo = TRUE} 
The column `tanf_spell_months` has the number of months in that spell.
  
```
The question is asking us about spell lengths, so we aggregate to count the number of persons with a spell of a given length.

```yaml
query <- "SELECT count(*),tanf_spell_months as length
FROM ada_tdc_2020.tanf_2016q4
GROUP BY length
ORDER BY count desc"

spell_count_df <- dbGetQuery(con, query)

```

<span style="color:green; ">What is the distribution of spell lengths amongst these individuals?</span>


We look at distribution of spell lengths in the 2016 Q4 cohort to answer this question.  We can use `summary(df)` to generate the quartiles and the median. 

```yaml
summary(spell_count_df)
```

We can also use `quantile` to calculate specific percentiles:
```{marginfigure echo = TRUE} 
We use the `$` sign notation to specify the `length` column, which is the column we're looking for a distribution on. The `c` function is used to create a vector of numbers for the percentiles we are looking for.
  
```

```yaml
quantile(spell_count_df$length, c(0.1, 0.25, 0.5, 0.75, 0.8))
```

We can also use the `SQL` function `percentile_cont` to calculate the 25th percentile.  

```yaml
query <- "SELECT
percentile_cont(0.25) 
WITHIN GROUP (ORDER BY tanf_spell_months) as percentile_25
FROM ada_tdc_2020.tanf_2016q4
```

We can extend the query to calculate other percentile values, and use `unnest` function to see the percentile value with the percentile.

```yaml
query <- "SELECT unnest(
                   percentile_cont(array[0.1,0.25,0.5,0.75,0.9]) 
                   WITHIN GROUP (ORDER BY tanf_spell_months)
                ) AS months,
                unnest(array[0.1,0.25,0.5,0.75,0.9]) as percentile_value
FROM ada_tdc_2020.tanf_2016q4
```

<span style="color:red; font-weight: bold;">CHECKPOINT 1:</span>


Modify the query used to calculate distirbution of spell lengths to calculate the same for the 2009 Q1 cohort.  The cohort is stored in the the query used to calculate distribution of spell lengths using `sprintf` to calculate the distribution for the cohort exiting in Q1 2009. 

<span style="color:red; font-weight: bold; font-style: italic;">Solution:</span>

```yaml
tbl <- tanf_2009q1

base_query <- "SELECT unnest(
                   percentile_cont(array[0.1,0.25,0.5,0.75,0.9]) 
                   WITHIN GROUP (ORDER BY tanf_spell_months)
                ) AS months,
                unnest(array[0.1,0.25,0.5,0.75,0.9]) as percentile_value
FROM ada_tdc_2020.%s"

query <- sprintf(base_query,tbl)
```

### Summary Statistics: Wages

**Guiding Questions:**     

We are interested in the earnings and employment characteristics of TANF leavers in their 1st and 5th quarters post-exit.
```{marginfigure echo = TRUE}
Introduce `sprintf` function for making queries flexible by creating a placeholder for `yr_quarter` and the table name to calculate distribution of earnings in both cohorts, 1st and 5th quarter post exit   
```
    
    
1.  What is the shape/form of the wage tables?  
1.  How many total jobs did leavers hold in the 1st and 5th quarter post-exit?   
1.  How many individuals were working those jobs?  
1.  What was the distribution of wages in the 1st and 5th quarter post-exit?  
1.  What is the employment and earnings (number of jobs, total wages) of individuals in our 2016 Q4 cohort in the quarter after exit?
1.  What was the proportion of TANF individuals with a job in the 8 quarters after their exit?
1.  What was the proportion of TANF individuals with a stable job in the 8 quarters after their exit? `r margin_note('in 2019, this was how many had it in the year 2017, but i didnt see a calculation that filtered just to this year')`
1.  How many TANF individuals do not have available wage data in our cohort?


**Tables:**
These calculations rely on `ada_tdc_2020.tanf_wage_<year>q<quarter>` which contain wage records for individuals in the corresponding cohort from the quarter of exit until 8 quarters post-exit.
`r margin_note('we may want to talk over this one/confirm. based on 2019 tdc')`


First, we preview the data in the wage cohort tables.

```yaml
dbGetQuery(con, "SELECT * FROM ada_tdc_2020.wage_2016q4 limit 5;)
```
<span style="color:green; "> How many total jobs did leavers hold in the 1st and 5th quarter post-exit?</span>

```{marginfigure, echo=TRUE}
Aggregate the total number of jobs with `count(*)`, since each row is a job. Group by 1st and 5th quarter after exit (Q1 2017 and Q1 2018, respectively).
```

```yaml
query <- "SELECT
job_yr_q, count(*)
FROM ada_tdc_2020.wage_2016q4
WHERE job_yr_q in ('2017-01-01', '2018-01-01')
GROUP BY job_yr_q
ORDER BY job_yr_q asc"
```
   
<span style="color:green; ">How many persons were working those jobs?</span>
```{marginfigure, echo=TRUE}
Aggregate the total number of persons with `count(distinct(ssn))`, since each row is a job and any individual ssn may have multiple jobs. Group by 1st and 5th quarter after exit (Q1 2017 and Q1 2018, respectively).
```

```yaml
query <- "SELECT
job_yr_q, count(distinct(ssn))
FROM ada_tdc_2020.wage_2016q4
WHERE job_yr_q in ('2017-01-01', '2018-01-01')
GROUP BY job_yr_q
ORDER BY job_yr_q asc"
```

<span style="color:green; ">What is the distribution of wages in the 1st quarter after exit?</span>

```{marginfigure, echo=TRUE}
Calculate percentiles at the 10th, 25th, 50th, 75th and 90th percentiles using the PostgreSQL function `percentile_cont` in the 1st quarter after exit. 
```

```yaml
query <- "SELECT unnest(
                   percentile_cont(array[0.1,0.25,0.5,0.75,0.9]) 
                   WITHIN GROUP (ORDER BY wages)
                ) AS earnings_value,
                unnest(array[0.1,0.25,0.5,0.75,0.9]) as percentile_value
FROM ada_tdc_2020.wage_2016q4
WHERE job_yr_q = '2017-01-01'
```
```{marginfigure, echo=TRUE}
**Checkpoint 2 Learning Objectives**:     
Adding multiple placeholders in different places in the SQL query using `sprintf`
```
<span style="color:red; font-weight: bold;">CHECKPOINT 2:</span>

Modify the queries using the `sprintf` function to make it easy to re-run for the 2009 cohort. 

Modify queries used to produce these measures:  
- Number of jobs   
- Number of people working those jobs   
- Distribution of earnings in a quarter after exit (you will need 2 placeholders - table and quarter).    

<span style="color:red; font-weight: bold; font-style: italic;">Solution:</span>

```yaml
query <- "SELECT 
job_yr_q, count(distinct(ssn))
FROM ada_tdc_2020.wage_2016q4
WHERE job_yr_q = '2017-01-01'"
```
turns into 

```yaml
table_name <- "ada_tdc_2020.wage_2016q4"
job_yr_q <- '2017-01-01' 

base_query <- "SELECT job_yr_q, count(distinct(ssn))
FROM ada_tdc_2020.%s
WHERE job_yr_q = '%s'"

query <- sprintf(base_query, table_name, job_yr_q)
```
```{marginfigure, echo=TRUE}
**Checkpoint 3 Learning Objectives**:   
Compare distribution of earnings in different cohorts and quarters since exit, using the parameterized query created in **Checkpoint 2**
```

<span style="color:red; font-weight: bold;">CHECKPOINT 3:</span>
With the parameterized query created in **Checkpoint 2**, calculate the distribution of earnings for:  
- 2016 Q4 Cohort, 5 months post-exit  
- 2009 Q1 Cohort, 1 month post-exit  
- 2009 Q1 Cohort, 5 months post-exit  


From now on, we will parameterize all SQL queries where we can, since the goal of our analyses is to compare two cohorts at different points after they exit TANF.

<span style="color:green; ">What is the employment and earnings (number of jobs, total earnings) of individuals in our cohort?</span>

Calculate number of jobs and total wages per person in a given quarter post-exit. In the notebook, we do this only for the first 100 rows to reduce computational power needed. We filter to look at the 1st quarter post-exit with the `year` and `quarter` columns (intead of `job_yr_q`) to demonstrate use of the `%d` placeholder.



```yaml
`r code_snips$code[code_snips$title=="num_wage_jobs_by_ssn_input"]`

`r code_snips$code[code_snips$title=="num_wage_jobs_by_ssn_base_query"]`

`r code_snips$code[code_snips$title=="num_wage_jobs_by_ssn_query"]`

```

We just saw a non-random sample of the number of jobs per person. Now, we calculate a distribution to give us a fuller picture.`r margin_note('i did a distribition on this - it wasnt in the tdc 2019 notebook')`

<span style="color:green; ">What is the distribution of employment and earnings (number of jobs, total wages) of individuals in our cohorts?</span>


```yaml
`r code_snips$code[code_snips$title=="dist_wages_num_jobs_input"]`

`r code_snips$code[code_snips$title=="dist_wages_num_jobs_base_query"]`

`r code_snips$code[code_snips$title=="dist_wages_num_jobs_query"]`

```

Now we turn to looking at the participation of our TANF cohorts in the job market. 

<span style="color:green; ">Among TANF leavers in our cohort, what was the proportion who had a job at any time during the 8 quarters post-exit?</span>  

First we calculate the number of individuals who had any employment in the wages. This will be the numerator. 
```yaml
`r code_snips$code[code_snips$title=="num_tanf_employed"]`

```

Then we calculate the denominator, # individuals in the exit cohort, to find the proportion amongst all TANF leavers. 
```yaml
`r code_snips$code[code_snips$title=="num_tanf"]`

`r code_snips$code[code_snips$title=="rate_tanf_employed"]`

```

Now we will repeat these proportion calculations, but look at the _stably employed_. What do we mean when we say stable employment? There are a number of measures that speak to the stability of employment: full quarter employment, full year employment, or employment earning over a certain threshold. Here, we will calculate full quarter employment, meaning employment at the same firm for 3 consecutive quarters. This is a `CROSS JOIN` and in order to parameterize, we can still use `sprintf` but the placeholder is `%1$s` instead of `%s`. We also use the `rep` function to generate the input to `sprintf`. See [table_creation](table_creation.html) for more. 

<span style="color:green; ">Among all TANF leavers, what was the proportion of TANF individuals with a stable job at any time during the 8 quarters post-exit? Among employed TANF leavers, what was the proportion who were stably employed?</span>
First we calculate the number of individuals who had three consecutive quarters of employment with the same employer. This will be the numerator. 
```yaml

`r code_snips$code[code_snips$title=="num_stable_employed"]`

```

Then we use the values calculated earlier as the denominators. First, we calculate the proportion amongst all employed TANF leavers. 

```yaml
`r code_snips$code[code_snips$title=="rate_stable_employed"]`

```

Then we calculate the proportion amongst all TANF leavers. 
```yaml

`r code_snips$code[code_snips$title=="rate_stable_tanf"]`

```


<span style="color:red; font-weight: bold;">CHECKPOINT 4:</span>
We just calculated full quarter employment for the 2016 Q4 cohort. Now calculate it for the 2009 Q1 cohort.
`r margin_note('come up with a better checkpoint?')`

## Employer
### Summary Statistics: Employer Characteristics

**Guiding Questions:**  

We want to look at characteristics of firms that employ TANF leavers and all employers. TANF Employers are those employers who had at least one ssn from our TANF cohorts in their wage records. 

1.  What is the employment (total, stable) of firms employing TANF leavers?
1.  What is the payroll/earnings (total, average, stable) of these firms?
1.  In which industries do leavers find stable employment?
1.  Other measures of (turnover, earnings of workers in different percentiles)
    
First let's take a quick look the form of the employer characteristics tables:

<span style="color:green; ">What is the employment (total and stable) of employers?</span>
<span style="color:green; ">In which industries do leavers find stable employment?</span>


# SCRAP
```{marginfigure ECHO = TRUE}
**Columns**
  
`uiacct` - firm identifier 
`naics_3_digit` - NAICS code indicating industry type
`size` - # unique SSNs employed at the firm in the first quarter post-exit
```


We begin looking at characteristics of the firms that employ TANF leavers in our cohorts. The tables we will read from are `ada_tdc_2020.tanf_2016q4_empl` and `ada_tdc_2020.tanf_2009q1_empl`.

<span style="color:green; ">In which industries do leavers find stable employment?</span>

```yaml
cohort <- "2016q4"

base_query <- "SELECT *
FROM ada_tdc_2020.tanf_%s_empl
limit 100;


query <- sprintf(base_query, cohort)

df <- dbGetQuery(con, query)
```

We will answer this by aggregating with the `group_by` and `count` functions from `dplyr` (part of the `tidyverse`). This is our first time aggregating in R - all previous aggregations were done in SQL.

Pipe operator `%>%`

```yaml
df %>% dplyr::group_by(naics_3_digit) %>% count()
```
<span style="color:green; ">How many individuals does the firm employ?</span>

Again we will answer this using R - specifically the `quantile` function from the `stats` library.

```yaml
stats::quantile(df$size, probs = c(0.1,0.25,0.5,0.75,0.9))

```
**I'm pretty sure the remaining questions below do NOT go in data exploration - instead, ML prep like OSU**
1.  How many individuals does the firm employ? Total? `r margin_note('julia included a question about how many ppl does the firm stably employ - just want to make sure that belongs in data exploration. confirm that these earnings measures for the firm side should be here - i think they are in ML prep in OSU')`
1.  What are the wages paid by the firm? Calculate total, average and stable wages.   
1.  Other measures (turnover, earnings of workers in different industries)    


miscellaneous stuff from notebooks I was referencing  


- for how long have they been recieving benefits?  
- caan we find out how much each individual was making and how many jobs they had in 2016 Q4?
- what was the proportion of TANF individuals with a stable job in 2017?
- how many TANF individuals do not have available wage data in our cohort?

NOte that we dont have a QWI notebook (should we?)
- \# of jobs by post-exit quarter (1st and 5th)   
    - \# persons working those jobs by post-exit quarter (1st and 5th)   
    - Distribution of wages in 1st quarter post-exit   
    - \# of jobs per ssn    
    - Distribution of \# of jobs per ssn      

