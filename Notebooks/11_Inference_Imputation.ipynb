{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"400\">\n",
    "</center>\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "<center> Julia Lane, Clayton Hunter, Brian Kim, Benjamin Feder, Ekaterina Levitskaya, Tian Lou, Lisa Osorio-Copete. \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome measurement and imputation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "What should you do when you encounter missing values in your data? Unfortunately, there is usually no *right* answer. However, you can try to impute these missing values, providing your best guess for each missing point's true value. Here, you will learn how to implement common imputation methods you can use in approaching missing values in your own work.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "* Gain understanding of the concept of measurement error in the context of a cohort's earnings\n",
    "\n",
    "* Explore options for imputing missing values\n",
    "\n",
    "* Visualize estimate changes following imputation\n",
    "\n",
    "In this notebook, you will focus on the earnings of individuals who were the primary recipients of TANF spells ending in 2016Q4 during their first year after this TANF spell completion, particularly in their first and fourth quarters after leaving the TANF program. Recall that in the [Data Exploration](03_Dataset_Exploration.ipynb/#Post-TANF-Employment-Outcomes) notebook, you initially examined the earnings distribution for all members of this cohort who had positive earnings in this time period in Indiana. To evaluate the earnings outcomes of all primary recipients of TANF spells ending in 2016Q4 in Indiana, you need to decide what to do when you cannot find their earnings in the Indiana Unemployment Insurance (UI) wage records. A person may not appear in Indiana's UI wage records for several reasons:\n",
    "- The person is unemployed. \n",
    "- The person is out of labor force, e.g., schooling, childcare, etc...\n",
    "- The person was employed outside of the state.\n",
    "- The person's job is not covered in UI wage records, e.g.,self-employed, independent contractors, federal government works, etc. <a href='https://www.nap.edu/read/10206/chapter/11#294'>(Hotz and Scholz, 2002)</a>\n",
    "\n",
    "You will explore the resulting earnings outcomes after applying different earnings imputation methods. The methods covered in this notebook include:\n",
    "- Dropping all \"missing\" values\n",
    "- Filling in zero for people who do not have records in Indiana UI wage records data \n",
    "- Substituting missing values with the average earnings of people who received TANF benefits from the same county and have the same gender\n",
    "- Regression imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Setup and Database Connection\n",
    "\n",
    "Before you begin, you need to run the code cells below to import the libraries and connect to our PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database interaction imports\n",
    "library(DBI)\n",
    "library(RPostgreSQL)\n",
    "\n",
    "# for data manipulation/visualization\n",
    "library(tidyverse)\n",
    "\n",
    "# scaling data, calculating percentages, overriding default graphing\n",
    "library(scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RPostgreSQL driver\n",
    "drv <- dbDriver(\"PostgreSQL\")\n",
    "\n",
    "# connect to the database\n",
    "con <- dbConnect(drv,dbname = \"postgresql://stuffed.adrf.info/appliedda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Manipulation: Isolating Earnings during first quarter after exit\n",
    "\n",
    "Before we start performing imputation, we need to do some quick data manipulation to isolate earnings from the first quarter after each individual's exit. Luckily, the first quarter after exit is simply where `quarter` is equal to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table into R\n",
    "qry <- \"\n",
    "select *\n",
    "from ada_tdc_2020.cohort_2016_earnings\n",
    "\"\n",
    "df_2016_wages <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in quarter after graduation\n",
    "q1_wages <- df_2016_wages %>%\n",
    "    filter(quarter == 1)\n",
    "\n",
    "# see unique values of quarter\n",
    "q1_wages %>%\n",
    "    distinct(quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will want to estimate the total wages for each `ssn` in this quarter, not necessarily their wages per employer, let's aggregate `q1_wages` to find the total earnings for each member of this cohort in the entire quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate on ssn\n",
    "q1_wages <- q1_wages %>%\n",
    "    group_by(ssn) %>%\n",
    "    summarize(tot_wages = sum(wages)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(q1_wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_num <- q1_wages %>%\n",
    "    summarize(n=n_distinct(ssn))\n",
    "\n",
    "cat('The total number of primary recipients with positive earnings during their first quarter after ending their 2016Q4 TANF spell:', q1_num$n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the percentage of our cohort represented in `q1_wages`, let's load in our original cohort into R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016Q4 cohort with most recent case information\n",
    "qry <- \"\n",
    "SELECT *\n",
    "FROM ada_tdc_2020.cohort_2016\n",
    "\"\n",
    "\n",
    "#read into R as df\n",
    "df_2016 <- dbGetQuery(con,qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat('That is', percent(q1_num$n/nrow(df_2016), .01), 'of the study cohort.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Checkpoint 1: Identifying Earnings in the Fourth Quarter after ending a TANF spell in 2016Q4 </h3>\n",
    "\n",
    "Given the code above, create a data subset `q4_wages` that contains all earnings for the cohort in their fourth quarter after leaving the TANF program. How many members of the cohort had positive earnings in this quarter? Did you expect this number to be higher or lower than the number in the first quarter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add leavers without positive earnings for Q1\n",
    "\n",
    "Our current data frame, `q1_wages`, only contains individuals with positive earnings in their first quarter after exit in Indiana. Let's add in members of our cohort who did not appear in Indiana's wage records during this time period, as well the additional variables from the original cohort table to better describe the individuals. This will let us easily analyze different earnings distributions in the cohort's first quarter after exit as we progress throughout this notebook.\n",
    "\n",
    "We can do so by using a `left_join()` of the original cohort, `df_2016`, to `q1_wages`, as this will add in one row for each `ssn` in the original cohort that was not included in `q1_wages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in employment outcomes for all of those in the original cohort\n",
    "q1_all_wages <- df_2016 %>%\n",
    "    left_join(q1_wages, c(\"ssn\"))\n",
    "\n",
    "# see data frame\n",
    "head(q1_all_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check, we can see if the number of individuals in `q1_all_wages` that either have or do not have null wages makes sense given the total number of individuals in the cohort that were in `q1_wages`. We can do so by adding in an indicator variable if the `wages` column was null for each potential wage record in `q1_all_wages`, and then counting the number of distinct individuals based on this new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employment outcomes for all of those in our original cohort\n",
    "q1_all_wages %>%\n",
    "    mutate(wage_ind = ifelse(is.na(tot_wages), 'no', 'yes')) %>%\n",
    "    group_by(wage_ind) %>%\n",
    "    summarize(n=n_distinct(ssn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of individuals in q1_wages\n",
    "q1_num$n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these numbers make sense. If they did not add up, chances are there was an issue with the details of the join.\n",
    "\n",
    "For future usage, let's add the gender to each individual in `q1_all_wages`. This variable can be accessed within the table `person_month` in the `in_fssa` schema. Let's load the contents of this table into R in preparation for the join, but only the contents for those in the original cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load person_month into R\n",
    "qry <- \"\n",
    "select *\n",
    "from in_fssa.person_month\n",
    "where ssn in (select ssn from ada_tdc_2020.cohort_2016)\n",
    "\"\n",
    "person_month <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see every individual is in person_month\n",
    "n_distinct(person_month$ssn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there may be more than one row in `person_month` corresponding to each individual, as `person_month` contains a record for every month the individual was associated with any TANF case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many rows we have in person_month\n",
    "nrow(person_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now `left_join()` `person_month` to `q1_all_wages` to find the corresponding gender value for each individual in `q1_all_wages`. To ensure we are just selecting these specific columns pertaining to the proper `caseid`, `month` and `tanf_end` indicator from `master_person`, we will include them as well as variables on which to join in our code below.\n",
    "\n",
    "> Additionally, we will de-select all repetitive columns in `q1_all_wages` and `person_month` that were not included in the join conditions, as they will not provide any statistical power for the following analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join and de-select unneccessary variables and see the names of the columns\n",
    "q1_all_wages %>%\n",
    "    left_join(person_month, c('ssn', 'caseid', 'month', 'tanf_end')) %>%\n",
    "    select(-c(ends_with('.x'), ends_with('.y'))) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update q1_all_wages\n",
    "q1_all_wages <- q1_all_wages %>%\n",
    "    left_join(person_month, c('ssn', 'caseid', 'month', 'tanf_end')) %>%\n",
    "    select(-c(ends_with('.x'), ends_with('.y')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to confirm, we can check to see if the number of rows in `q1_all_wages` is equal to the number of rows in `df_2016`, the original cohort, as each individual in the original cohort should correspond to a single row regardless of employment status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(df_2016) == nrow(q1_all_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check to see if we have any missing values for our `gender`, `dob_yr`, and `county` variables. If so, let's fill these in as `unknown` so these rows will not be dropped in future analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see number of na values for gender and dob_yr\n",
    "colSums(is.na(q1_all_wages[c('gender', 'dob_yr', 'county')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Checkpoint 2: Replicate for Q4</h3>\n",
    "\n",
    "Create a data frame `q4_all_wages` that mirrors `q1_all_wages` except for Q4. Feel free to add in as many code cells as you deem necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Wage Values\n",
    "\n",
    "Now that we have confirmed that our `q1_all_wages` dataframe is ready to use for testing our imputation methods, we can get started. To recall, here are the four methods we will be trying out in this notebook:\n",
    "- Dropping all \"missing\" values\n",
    "- Filling in zero for people who do not have records in Indiana UI data\n",
    "- Filling in missing values with the average earnings of people who received benefits from the same county and have the same gender\n",
    "- Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Drop All Missing Values\n",
    "\n",
    "First, let's look at the earnings outcomes during first quarter after TANF exits in 2016Q4 when we drop all missing earnings values. Here, by ignoring potentially non-missing values, we are hoping that they mirror the same distribution as the present one. Although this is fairly common, you should **never, ever, ever** use this method in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "q1_no_missing <- q1_all_wages %>%\n",
    "    filter(!is.na(tot_wages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see earnings distribution\n",
    "summary(q1_no_missing$tot_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red\">Checkpoint 3: Replicate for Q4</h4>\n",
    "\n",
    "What does the earnings distribution look like for Q4 when you drop missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fill in Missing Values with Zero\n",
    "\n",
    "Next, let's see how the earnings distribution shifts when we encode all missing earnings outcomes as 0. Here, we are assuming that all missing earnings are due to unemployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all null tot_wages with 0\n",
    "q1_wages_zero <- q1_all_wages %>%\n",
    "    mutate(tot_wages = ifelse(is.na(tot_wages), 0, tot_wages)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the distribution. How does it vary from the distribution you get in method 1?\n",
    "summary(q1_wages_zero$tot_wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat('Average earnings if missing wages are dropped is $', round(mean(q1_no_missing$tot_wages), 2), sep = '', '.')\n",
    "\n",
    "cat('\\nAverage earnings if missing wages are imputed as 0 is $', round(mean(q1_wages_zero$tot_wages), 2), sep = '', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red\">Checkpoint 4: Replicate for Q4</h4>\n",
    "\n",
    "What does the earnings distribution look like for Q4 when you fill missing values with zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fill in Missing Values with County/Gender Mean Earnings\n",
    "\n",
    "Now, instead of either ignoring missing values or assuming the earnings are 0, we will try imputing missing earnings for each individual as the average quarterly earnings of the other individuals in our cohort of the same `gender` and `county`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our strategy is as follows:\n",
    "- Find mean earnings for each `county` by `gender`\n",
    "- Merge the mean earnings for each `county` by `gender` to quarterly earnings for each member of the cohort by `county`/`gender` combination\n",
    "- If the earnings are null, replace with mean earnings of `county`/`gender` combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(q1_all_wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean earnings by gender/county grouping\n",
    "q1_all_wages %>%\n",
    "    group_by(gender, county) %>%\n",
    "    summarize(mean_wages = mean(tot_wages, na.rm=T)) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean earnings by gender/county grouping saved\n",
    "q1_county_gend <- q1_all_wages %>%\n",
    "    group_by(gender, county) %>%\n",
    "    summarize(mean_wages = mean(tot_wages, na.rm=T)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will merge the two DataFrames, `q1_county_gend` and `q1_all_wages` using `inner_join`.\n",
    "> Note: `left_join()` would also work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if join works\n",
    "q1_all_wages %>%\n",
    "    inner_join(q1_county_gend, by=c('gender', 'county')) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save join results to q1_joined_county_gend\n",
    "q1_joined_county_gend <- q1_all_wages %>%\n",
    "    inner_join(q1_county_gend, by=c('gender', 'county'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can add a new column to `q1_joined_county_gend` to include the mean `county`/`gender` wage if the individual did not appear in the Indiana UI wage records data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if mutation works as designed\n",
    "q1_joined_county_gend %>%\n",
    "    mutate(imputed_wages = ifelse(is.na(tot_wages), mean_wages, tot_wages)) %>%\n",
    "    select(tot_wages, mean_wages, imputed_wages) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mutation to q1_major_gend_impute\n",
    "q1_county_gend_impute <- q1_joined_county_gend %>%\n",
    "    mutate(imputed_wages = ifelse(is.na(tot_wages), mean_wages, tot_wages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In using this method, there is a chance we cannot impute missing values for all individuals in the cohort. If `imputed_wages` is still `NA`, we can assume there were no individuals in the cohort with non-missing earnings with the same `county`/`gender` combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if any still don't have imputed earnings\n",
    "q1_county_gend_impute %>%\n",
    "    filter(is.na(imputed_wages)) %>%\n",
    "    summarize(n=n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it seems as though we do not have available earnings for every combination of `gender` and `county`. For the sake of the exercise, we will ignore the earnings of those whose we could not impute using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(q1_county_gend_impute$imputed_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red\">Checkpoint 5: Replicate for Q4</h4>\n",
    "Impute missing earnings values as the mean earnings of individuals in the cohort with the same `gender` and `county` fields. What does the earning distribution look like? For how many individuals could you not impute values using this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regression imputation\n",
    "\n",
    "We can also use regression to try to get more accurate earnings values. We will build a regression equation from the obervations for which we know the earnings, then use the equation to predict the missing earnings values. This is, in effect, an extension of the mean imputation by subgroup. Here, we will use demographic information of graduates such as birth year, gender, race, and education level.\n",
    "\n",
    "> Note: We will not be checking the assumptions associated with linear regressions, as this example is aimed at merely displaying how to use a linear regression for imputation. If you plan on using regression imputation, please check all assumptions before employing a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to variables included in regression analysis\n",
    "q1_reg <- q1_all_wages %>%\n",
    "    select(ssn, tot_wages, dob_yr, gender, hispan, native, asian, black, hawaia, white, edul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see types of the variables\n",
    "glimpse(q1_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the data dictionary, all education levels from `01`-`11` correspond to the same grouping. Let's reflect that in `q1_reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morph edul variable to reflect data dictionary\n",
    "q1_reg <- q1_reg %>%\n",
    "    mutate(edul = ifelse(as.numeric(edul) < 12, '01-11', edul))\n",
    "\n",
    "# see result\n",
    "q1_reg %>%\n",
    "    select(edul) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will build the model using the members of our cohort with non-missing wages, we will split `q1_reg` into two datasets, one for testing (`q1_wages_na`) and one for training (`q1_wages_pred`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "# don't need tot_wages because they are null \n",
    "q1_wages_na <- q1_reg %>%\n",
    "    filter(is.na(tot_wages)) %>%\n",
    "    select(-c(tot_wages))\n",
    "\n",
    "q1_wages_pred <- q1_reg %>%\n",
    "    filter(!is.na(tot_wages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model creation process for a linear regression can be done using the `lm()` function. The variable we are trying to predict is on the left-hand side of `lm()` before the `~`, and the predictors are all of the variables on the right-hand side of the `~`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model and fit coefficients\n",
    "q1_wages_model <- lm(tot_wages ~ dob_yr + gender + hispan + native + asian + black + hawaia + white + edul, data = q1_wages_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fit coefficients for each of the predictors in the model, we can predict the `tot_wages` variable for the test set using `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict earnings for test set\n",
    "pred_earnings <- data.frame(tot_wages = predict(q1_wages_model, newdata=q1_wages_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see predicted earnings\n",
    "head(pred_earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the output for `predict()` retains the same order of rows from `q1_wages_na`, we can add the `tot_wages` variable from `pred_earnings` into the existing `q1_wages_na` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see updated data frame with predicted earnings\n",
    "cbind(q1_wages_na, pred_earnings) %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated data frame\n",
    "q1_wages_na_w_earnings <- cbind(q1_wages_na, pred_earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before we can see the effects of the imputation method, we need to combine our training set, which already has `tot_wages`, with our testing set and its predicted `tot_wages`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine training and testing sets\n",
    "rbind(q1_wages_na_w_earnings, q1_wages_pred) %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save combined training and testing sets\n",
    "q1_reg_earnings <- rbind(q1_wages_na_w_earnings, q1_wages_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the entire earnings distribution for the cohort after applying regression imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see earnings distribution for full cohort\n",
    "summary(q1_reg_earnings$tot_wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see earnings distribution for imputed portion of cohort\n",
    "summary(q1_wages_na_w_earnings$tot_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h4> Checkpoint 6: Add in `citzn` and re-run the regression</h4></font> \n",
    "\n",
    "When you add `citzn` into the regression, how does the earnings distribution compare to the one using the previous linear regression to impute values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Earnings Distributions\n",
    "\n",
    "We can quickly determine if these different imputation methods significantly altered the pre-imputation wage distribution by visualizing the overall earnings distribution. Plotting side-by-side boxplots can be an effective choice. To do so, we need to bind the earnings from all of these methods by rows, meaning they must have the same columns. For the sake of simplicity, we will have three columns in this data frame:\n",
    "\n",
    "- `ssn`, the person identifier\n",
    "- `tot_wages`, cumulative earnings in first quarter post-exit\n",
    "- `method`, type of imputation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt q1_no_missing\n",
    "q1_no_missing %>%\n",
    "    select(ssn, tot_wages) %>% head()\n",
    "\n",
    "q1_no_missing <- q1_no_missing %>%\n",
    "    select(ssn, tot_wages) %>%\n",
    "    mutate(method = 'remove missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt q1_reg_earnings\n",
    "q1_reg_earnings%>%\n",
    "    select(ssn, tot_wages) %>% head()\n",
    "\n",
    "q1_reg_earnings <- q1_reg_earnings %>%\n",
    "    select(ssn, tot_wages) %>%\n",
    "    mutate(method = 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt q1_wages_zero\n",
    "q1_wages_zero %>%\n",
    "    select(ssn, tot_wages) %>% head()\n",
    "\n",
    "q1_wages_zero <- q1_wages_zero %>%\n",
    "    select(ssn, tot_wages) %>%\n",
    "    mutate(method = 'zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapt q1_county_gend_impute\n",
    "q1_county_gend_impute %>% \n",
    "    select(ssn, imputed_wages) %>% \n",
    "    rename(tot_wages = imputed_wages) %>% \n",
    "    head()\n",
    "\n",
    "q1_county_gend_impute <- q1_county_gend_impute %>%\n",
    "    select(ssn, tot_wages) %>%\n",
    "    mutate(method = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that these methods all have the same column names, we can feed them into `rbind()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine earnings from all methods\n",
    "all_methods <- rbind(q1_county_gend_impute, q1_reg_earnings, q1_no_missing, q1_wages_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of plotting the earnings distributions of each method one at a time, we can plot them all in a side-by-side fashion by using the `facet_grid()` function as we did in the Data Visualization [notebook](05_Data_Visualization.ipynb/#Distribution-of-quarterly-wages-by-degree-rank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of all methods\n",
    "all_methods %>%\n",
    "    ggplot(aes(x=tot_wages, y ='')) +\n",
    "    geom_boxplot() + \n",
    "    facet_grid(method ~ .) +\n",
    "    labs(\n",
    "        title = \"REDACTED\",\n",
    "        x='Quarter 1 Earnings',\n",
    "        y='Method',\n",
    "        caption = 'Source: Indiana TANF and UI Wage Records data'\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple histograms\n",
    "\n",
    "We can also look at the differences in the earnings distribution by looking at side-by-side histograms. Instead of using the `geom_` layer `geom_boxplot()`, we will use `geom_histogram()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_methods %>%\n",
    "    ggplot(aes(x=tot_wages)) +\n",
    "    geom_histogram() + \n",
    "    facet_grid(method ~ .) +\n",
    "    labs(\n",
    "        title = 'REDACTED',\n",
    "        y = 'Density',\n",
    "        x='Quarterly Wages',\n",
    "        caption = 'Source: Indiana TANF and UI Wage Records data'\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Advanced: Using machine learning to impute values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To impute values, we can also use machine learning algorithms such as `K-nearest Neighbors` and `Decision Trees`. The principle behind `K-nearest Neighbors` is quite simple: the missing values can be imputed by values of \"closest neighbors\" - as approximated by other, known, features. \n",
    "\n",
    "For example, if we had cases where the data on earnings of some graduates was completely missing, we could approximate their earnings by referring to other characteristics which could be shared by major group (their 'closest neighbors' in terms of characteristics).\n",
    "\n",
    "The algorithm calculates the distance between the input values (the missing values) and helps to identify the nearest possible value based on other features (such as known characteristics of the closest major group). Imputing missing data using machine learning has become a research hotbed, and there are plenty of papers covering the various algorithms if you are curious."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "adrf_r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
