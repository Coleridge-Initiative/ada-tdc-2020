{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"400\">\n",
    "</center>\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "<center> Julia Lane, Clayton Hunter, Brian Kim, Benjamin Feder, Ekaterina Levitskaya, Tian Lou, Lisa Osorio-Copete. \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to use different visualization methods in R to explore and analyze your data. We will also talk about proper annotation of graphs in order to be able to clearly and accurately communicate your results.\n",
    "\n",
    "We will cover the following methods:\n",
    "- **Histogram** \n",
    "(visualizing distributions, continuous variables)\n",
    "- **Bar plot**\n",
    "(visualizing relationships between numerical and categorical variables)\n",
    "- **Small multiples**\n",
    "(using a series of mini-graphs to compare information by different groups)\n",
    "- **Heatmap** \n",
    "(adding highlights to your data with color-coding)\n",
    "- **Geographic heatmap**\n",
    "(showing regional differences in your data)\n",
    "\n",
    "For all visualizations we are going to use an R package called `ggplot2` (`ggplot2` is included in the `tidyverse` suite of packages). The syntax of `ggplot2` in most cases stays the same:\n",
    "\n",
    "- you always start with `ggplot()` <br>\n",
    "- then, supply a dataset and aesthetic mapping - x and/or y variables, like this: `ggplot(dataset, aes(x = ..., y = ...)` <br>\n",
    "- and then you can add layers using `+` <br>\n",
    "for example, <br>\n",
    "`ggplot(dataset, aes(x = ... , y = ...) + geom_histogram()` to create a histogram, or <br>\n",
    "`ggplot(dataset, aes(x = ... , y = ...) + geom_histogram() + ggtitle('My plot title')` to create a histogram and add a title for the graph, and so on.\n",
    "\n",
    "In this notebook we will visualize the following examples for our 2016Q4 cohort (defined in the Data Exploration notebook):\n",
    "\n",
    "- TANF experience:\n",
    "    - **Top 10 counties by number of TANF leavers** (bar plot)\n",
    "    - **Number of TANF leavers by county** (geographic heatmap)\n",
    "    - **Distribution of spell lengths in the cohort** (histogram)\n",
    "    \n",
    "\n",
    "- Employment outcomes:\n",
    "    - **Distribution of wages in 5 most popular industries** (small multiples)\n",
    "    - **Most popular industries with the highest average wages** (bar plot)\n",
    "    - **Employment patterns by quarters** (heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing necessary R libraries and connecting to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database interaction imports\n",
    "library(DBI)\n",
    "library(RPostgreSQL)\n",
    "\n",
    "# for data manipulation/visualization\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "library(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RPostgreSQL driver\n",
    "drv <- dbDriver(\"PostgreSQL\")\n",
    "\n",
    "# connect to the database\n",
    "con <- dbConnect(drv,dbname = \"postgresql://stuffed.adrf.info/appliedda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read-in a table for our 2016Q4 cohort that we used in the Data Exploration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016Q4 cohort with most recent case information\n",
    "qry <- \"\n",
    "SELECT *\n",
    "FROM ada_tdc_2020.cohort_2016\n",
    "\"\n",
    "\n",
    "#read into R as df\n",
    "df_2016 <- dbGetQuery(con,qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(df_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TANF experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 counties by number of TANF leavers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, it could be useful for us to visualize the differences in the number of TANF leavers by top 10 counties for 2016Q4 cohort. Bar plots can help you to visually inspect the differences between groups in your own data exploration work, and they are also an effective communication tool for the outside audience (for example, if you would like to highlight a significant difference between groups, as we do in the example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of leavers by county\n",
    "leavers_county <- df_2016 %>%\n",
    "                group_by(county) %>%\n",
    "                summarize(count=n()) %>%\n",
    "                arrange(desc(count)) %>%\n",
    "                slice(1:10)  # choose only top 10 counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(leavers_county)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to match the county codes to the names of the counties, we can load the `tl_2016_us_county` table from the `public` schema into R and join the two data frames, like we did in the Data Exploration notebook.\n",
    "\n",
    "> Indiana's state fips code is 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get county codes, county names, polygons, and centroids of those polygons for the Indiana state\n",
    "qry <- \n",
    "\"SELECT countyfp as county, name\n",
    "FROM public.tl_2016_us_county\n",
    "WHERE statefp = '18'\n",
    "\"\n",
    "#read into R as df\n",
    "counties <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see counties\n",
    "head(counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that similar to SQL's `LEFT JOIN`, one of the `tidyverse` packages, `dplyr`, contains `left_join()` which we can use to match the county codes to their proper names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join to county lookup table\n",
    "leavers_county <- leavers_county %>% \n",
    "    left_join(counties, by=\"county\") %>%\n",
    "    select(name, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leavers_county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use `ggplot` and `geom_bar` function to create a bar plot - with top 10 counties on the x-axis and counts of TANF leavers on the y-axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any graph, remember to always:\n",
    "- add a title (`ggtitle`) - title should ideally describe the main message/takeaway from the graph.\n",
    "- x and y labels (`xlab`, `ylab`)\n",
    "- data source for the graph (`labs(caption = ...`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the plot\n",
    "\n",
    "ggplot(leavers_county, aes(x=reorder(name, -count), y=count)) +    # use reorder() to order bars from high to low based on count\n",
    "geom_bar(stat = 'identity', fill = 'blue') +                       # add color here in the fill = ...\n",
    "ggtitle('REDACTED county: highest # of TANF leavers in 2016Q4') +    # add title here\n",
    "xlab('County') +                                                   # x-axis label\n",
    "ylab('Number of TANF leavers') +                                   # y-axis label\n",
    "theme(text=element_text(size=15, face=\"bold\"))  +                  # change font size of the graph\n",
    "labs(caption = 'Source: Indiana TANF data') +                      # add a caption below the plot\n",
    "theme(plot.caption = element_text(hjust=0)) +                      # this line of code adds caption in the left corner of the plot\n",
    "theme(axis.text.x = element_text(angle=90))                        # rotate labels on x-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 1: Recreate for 2009Q1 </h3></font> \n",
    "\n",
    "Recreate the same bar plot for the 2009Q1 cohort (the 2009Q1 cohort table is stored in the `ada_tdc_2020` schema as `cohort_2009`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TANF leavers by county - geographic heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to show regional differences in the number of TANF leavers by county using a map? A heatmap is a powerful visualization tool which allows to easily compare and communicate regional differences.\n",
    "\n",
    "We can leverage an available public table in our database with geographic coordinates of counties, and we will use an `sf` package, which allows us to read in geographic location information in one line of code (using `st_read` function) and prepare the data for plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of leavers by county\n",
    "leavers_county_map <- df_2016 %>%\n",
    "                group_by(county) %>%\n",
    "                summarize(count=n()) %>%\n",
    "                arrange(desc(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read in the necessary geographic information using `st_read` function in the `sf` package which prepares the data for plotting: county codes, county names, polygons, and centroids of those polygons for the Indiana state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get county codes, county names, polygons, and centroids of those polygons for the Indiana state\n",
    "qry <- \n",
    "\"SELECT countyfp as county, LOWER(name) as name, geom, ST_X(ST_Centroid(geom)) as long, ST_Y(ST_Centroid(geom)) as lat\n",
    "FROM public.tl_2016_us_county\n",
    "WHERE statefp = '18'\n",
    "\"\n",
    "#read into R as df\n",
    "counties <- st_read(con,query=qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we join `counties` dataframe with out dataset of TANF leavers' counts by county:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties <- inner_join(counties,leavers_county_map,by=\"county\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the map using `ggplot` and `geom_sf` as primary functions (and we will also add title, data source, and county names as labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "ggplot(counties) +   # insert the name of the main dataset here\n",
    "    geom_sf(aes(fill=count), color='white') +                   # in the fill parameter use \"count\" varable\n",
    "    scale_fill_gradient(low=\"light blue\",high=\"red\") +          # choose colors for the gradient\n",
    "    geom_text(aes(x=long, y=lat, label=name), size=2.3) +       # add county names as labels using centroids defined in the table\n",
    "    ggtitle(\"REDACTED County: highest # of TANF leavers in 2016Q4\") +   # add the title\n",
    "    theme(plot.title = element_text(size=15, face=\"bold\")) +          # change title font size and make the font bold\n",
    "    labs(caption = 'Source: Indiana TANF data') +                     # add a caption below the plot\n",
    "    theme(plot.caption = element_text(size=17, hjust=0))              # move caption to the left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 2: Recreate for 2009Q1 </h3></font> \n",
    "\n",
    "Recreate the same geographic heatmap for the 2009Q1 cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of spell lengths in the cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the summary statistics of spell lengths in the cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(df_2016$tanf_spell_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a histogram (`geom_histogram`) to inspect spikes and drops by the spell lengths in the cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the plot\n",
    "ggplot(df_2016, aes(tanf_spell_months)) + \n",
    "geom_histogram(bins=25, fill = 'blue') +\n",
    "ggtitle('Most Common Spell Length in 2016Q4 Cohort: REDACTED') +\n",
    "xlab('TANF spell months') +\n",
    "ylab('Number of individuals') +\n",
    "theme(text=element_text(size=12, face=\"bold\"))  +\n",
    "labs(caption = 'Source: Indiana TANF data') +\n",
    "theme(plot.caption = element_text(hjust=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 3: Recreate for 2009Q1 </h3></font> \n",
    "\n",
    "Recreate this histogram for the 2009Q1 cohort (or use your own variables of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employment outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of wages in 5 most popular industries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a density plot (a smoothed version of a histogram) to visualize distributions of wages in the 5 most popular industries among TANF leavers in 2016Q4 cohort. \n",
    "\n",
    "When we want to compare multiple groups in one plot, there is a high chance that the plot will become overcrowded. A good solution for such case is using small multiples (a series of mini-graphs for each gorup which use the same scale and axes) - in this example we will visualize wages distribution in 5 most popular industries using mini-density plots for each industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to read-in `cohort_2016_earnings` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table into R\n",
    "qry <- \"\n",
    "select *\n",
    "from ada_tdc_2020.cohort_2016_earnings\n",
    "\"\n",
    "df_2016_wages <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a table with the top 5 most popular industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save most popular naics as pop_naics\n",
    "pop_naics <- df_2016_wages %>%\n",
    "    group_by(naics_3_digit) %>%\n",
    "    summarize(num = n_distinct(ssn)) %>% \n",
    "    arrange(desc(num))  %>%\n",
    "    slice(1:5)    # choose top 5 industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_naics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wages for most popular industries\n",
    "wages_pop_naics <- df_2016_wages %>%\n",
    "    filter(naics_3_digit %in% pop_naics$naics_3_digit) %>%\n",
    "    select(ssn, wages, naics_3_digit, quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be useful to add NAICS industry code names - similar to how we did it in the Data Exploration notebook, we will use a table `naics_2017` in the `public` schema with the NAICS industry code names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the naics_2017 table\n",
    "qry <- '\n",
    "select *\n",
    "from public.naics_2017\n",
    "limit 5\n",
    "'\n",
    "dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read naics_2017 table into R as naics\n",
    "qry = '\n",
    "select *\n",
    "from public.naics_2017\n",
    "'\n",
    "naics = dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get industry names of most popular naics using left join, like we did in the Data Exploration notebook\n",
    "wages_pop_naics <- wages_pop_naics %>% \n",
    "    left_join(naics, by=c('naics_3_digit' = 'naics_us_code')) %>%\n",
    "    select(ssn, wages, naics_us_title, quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create small multiples in R, we will use `facet_grid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the small multiples plot\n",
    "ggplot(wages_pop_naics, aes(x = wages)) +                          # include the main dataset name and what variable to use on x-axis\n",
    "geom_density(fill = 'blue') +                                      # choose a fill color\n",
    "facet_grid(naics_us_title ~ .) +                                   # use facet grid\n",
    "theme(strip.text.y = element_text(angle=0, hjust=0)) +             # rotate text labels\n",
    "ggtitle('Cohort 2016Q4: Wages distribution in top 5 industries') + # add title\n",
    "xlab('Wages') +                                                    # add x-axis label\n",
    "ylab('Density') +                                                  # add y-axis label\n",
    "theme(text=element_text(size=14,face=\"bold\"))  +                   # change font size and make it bold\n",
    "labs(caption = 'Source: Indiana TANF, UI Wage data') +             # add data source caption\n",
    "theme(plot.caption = element_text(hjust=0))                        # move data source caption to the left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 4: Recreate for 2009Q1 </h3></font> \n",
    "\n",
    "Recreate small multiples for the 2009Q1 cohort (or use your own variables of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular industries with  the highest average wages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect top popular industries with the highest average wages and visualize those using a bar plot - to see if there are any drastic differences between the top industries (like we saw in the bar plot above for the differences in counties by number of TANF leavers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save most popular naics as pop_naics\n",
    "pop_naics <- df_2016_wages %>%\n",
    "    group_by(naics_3_digit) %>%\n",
    "    summarize(num = n_distinct(ssn)) %>% \n",
    "    arrange(desc(num))  %>%\n",
    "    slice(1:10)     # choose top 10 industries\n",
    "\n",
    "# get wages for top 10 industries\n",
    "wages_pop_naics <- df_2016_wages %>%\n",
    "    filter(naics_3_digit %in% pop_naics$naics_3_digit) %>%\n",
    "    select(ssn, wages, naics_3_digit, quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to quarterly_naics\n",
    "quarterly_naics <- wages_pop_naics %>%\n",
    "    group_by(ssn, quarter, naics_3_digit) %>%\n",
    "    summarize(tot_wages = sum(wages)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average quarterly wages by industry and include number of people employed at least one quarter in each industry\n",
    "top_mean_wages <- quarterly_naics %>%\n",
    "                group_by(naics_3_digit) %>%\n",
    "                summarize(avg_wages = mean(tot_wages),\n",
    "                         num_ssns = n_distinct(ssn)) %>%\n",
    "                arrange(desc(num_ssns)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mean_wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get industry names using left join with \"naics\" table, like we did above\n",
    "top_mean_wages <- top_mean_wages %>% \n",
    "    left_join(naics, by=c('naics_3_digit' = 'naics_us_code')) %>%\n",
    "    select(naics_us_title, avg_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you can use `reorder` function on the x-axis in order to sort the bars in the descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the plot\n",
    "ggplot(top_mean_wages, aes(x= reorder(naics_us_title, -avg_wages), y=avg_wages)) +\n",
    "geom_bar(stat = 'identity', fill = 'blue') +\n",
    "ggtitle('REDACTED - highest average wages (2016Q4)') +\n",
    "xlab('Industry') +\n",
    "ylab('Average wages') +\n",
    "theme(text=element_text(size=13, face=\"bold\"))  +\n",
    "labs(caption = 'Source: Indiana TANF, UI Wage data') +\n",
    "theme(plot.caption = element_text(hjust=0)) +\n",
    "theme(axis.text.x = element_text(angle=90))                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 5: Recreate for 2009Q1 </h3></font> \n",
    "\n",
    "Recreate the same bar plot for the 2009Q1 cohort (or use your own variables of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment Patterns by Quarters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last visualization that we would like to introduce in this notebook is a heatmap table of employment patterns of TANF leavers by quarters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that only a certain proportion of our cohort showed up in Indiana's UI wage records in the year after leaving TANF. It would logically follow that since not every individual in our cohort showed up in the UI wage records, not every individual would be represented in the `cohort_2016_earnings` table. Let's confirm that idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see amount of rows where wages are null\n",
    "qry = '\n",
    "select count(*)\n",
    "from ada_tdc_2020.cohort_2016_earnings\n",
    "where wages is null\n",
    "'\n",
    "dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at common employment patterns for our cohort, if we were to just use data from `cohort_2016_earnings`, we would be ignoring those who did not appear at all in the wage records. To address that issue, we can `LEFT JOIN` our full 2016 Q4 cohort to our current wage data frame `df_2016_wages`, and then we can work from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do the left join, remember how in the Data Exploration notebook we looked at the age breakdown of our cohort? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think it will make sense to include children under 18 years old in our employment patterns table? We would probably want to filter the dataframe only to adults. Let's do that first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recreate our 2016 Q4 cohort to include a date of birth variable in order to find out the age of TANF recipients, like we did in the Data Exploration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the cohort to include the date of birth variable (extract only year from the date of birth)\n",
    "qry <- \"\n",
    "SELECT distinct on (a.ssn)\n",
    "a.ssn, a.caseid, a.month, a.tanf_start, a.tanf_end, a.tanf_spell_months, a.tanf_total_months,b.county,\n",
    "substring(a.month,1,4) as rep_year, substring(a.month,5,2) as rep_month, extract(year from dob) as dob_yr  \n",
    "FROM in_fssa.person_month a\n",
    "INNER JOIN in_fssa.case_month b \n",
    "on a.caseid = b.caseid\n",
    "WHERE a.affil = '1' and\n",
    "a.tanf_end = TRUE and \n",
    "ssn not in (REDACTED) and\n",
    "substring(a.month,1,4) = '2016' and \n",
    "substring(a.month,5,2) in ('10','11','12')\n",
    "order by a.ssn, a.month desc;\n",
    "\"\n",
    "\n",
    "#read into R as df\n",
    "df_2016_age <- dbGetQuery(con,qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(df_2016_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with age\n",
    "df_2016_age <- df_2016_age %>%\n",
    "    mutate(age = as.integer(rep_year) - dob_yr) \n",
    "\n",
    "# Flag those who are 18 years old or older\n",
    "df_2016_age <- df_2016_age %>%    \n",
    "    mutate(age_ind = ifelse(age >= 18, \"adult\", \"non_adult\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(df_2016_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only those who are 18 years old or older, save to a dataframe called \"df_2016_adult\"\n",
    "df_2016_adult <- df_2016_age[df_2016_age$age_ind == \"adult\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(df_2016_adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can left join our `df_2016_adult` table with the `df_2016_wages`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join df_2016_adult to df_2016_wages\n",
    "total_df <- df_2016_adult %>%\n",
    "    left_join(df_2016_wages, c(\"ssn\", \"tanf_spell_months\", \"tanf_total_months\", \"county\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have earnings (or lackthereof) for our cohort, let's aggregate wages by quarter since we will eventually only want an indicator of whether an individual was employed in the quarter, which we can find by seeing if their wages for the quarter was greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by quarter\n",
    "agg_df <- total_df %>%\n",
    "    group_by(ssn, quarter) %>%\n",
    "    summarize(wages = sum(wages)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see that all missing wages are for those with no wages yet\n",
    "agg_df %>%\n",
    "    filter(is.na(wages)) %>%\n",
    "    summarize(n=n(),\n",
    "             num = n_distinct(ssn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we aggregate by quarter, we can still see that there is only one row for everyone in the cohort who has missing wages. Since we want our employment patterns table to encompass all four quarters, we need to create a data frame where each row corresponds to an `ssn` in our cohort, and then an indicator (`wages` > 0) if the individual was employed in the specific quarter. Thus, we need four entries per `ssn` to represent the four quarters of potential employment.\n",
    "\n",
    "To solve this problem, we can use `complete()`, which will \"complete\" a data frame based on all potential values of certain columns. We will want to `complete()` our data frame based on the `ssn` and `quarter` combinations, so we need to make sure our quarters span from 1 to 4 and our ssn's encompass all `ssn` values in our cohort.\n",
    "\n",
    "Let's check to see what the values of `quarter` are right now, and the amount of counts we have for each quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df %>%\n",
    "    group_by(quarter) %>%\n",
    "    summarize(n_distinct(ssn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the left join above, all members of our cohort (only adults) that did not appear in `df_2016_wages` have `NA` values for quarter. We need to fix that before we can use complete, so let's arbitrarily assign all rows with `NA` `quarter` values as Q1 so we can use `complete()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all where quarter is na equal to 1 so complete uses 1,2,3,4 as the options for quarter\n",
    "agg_df$quarter[is.na(agg_df$wages)] =1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can `complete()` `agg_df` based on all combinations of `ssn` and `quarter`, and for those that currently don't exist in `agg_df`, we can set their wages to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to complete df_2016_wages and fill out nas for all four quarters someone doesn't exist\n",
    "complete_df <- agg_df %>%\n",
    "    complete(ssn, quarter, fill=list(wages=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform a few sanity checks to make sure you used `complete()` properly for this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if number of rows of complete_df is 4 times the amount of rows in df_2016_adult (each ssn, quarter combo)\n",
    "nrow(complete_df) == nrow(df_2016_adult) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if number of ssns is same for complete_df and df_2016_adult\n",
    "n_distinct(complete_df$ssn) == n_distinct(df_2016_adult$ssn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see complete_df\n",
    "head(complete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add in our indicator variable based on whether an individual had earnings greater than 0 in a given quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new indicator column for if wages are greater than 0\n",
    "# then also get rid of the actual wages\n",
    "complete_df <- complete_df %>%\n",
    "    mutate(wage_ind = ifelse(wages == 0, \"no\", \"yes\")) %>%\n",
    "    select(-wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a row for every `ssn`/`quarter` combination and our indicator variable if the individual was employed in a given `quarter`, we can now morph our data frame into having each row as one `ssn`, with a \"yes\"/\"no\" indicator of employment for each quarter, which will be represented as individual columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now need to expand so that each quarter is a row \n",
    "# but first, need to expand a character/factor, not a numerical column\n",
    "complete_df <- complete_df %>%\n",
    "    mutate(new_quarter = case_when(\n",
    "    quarter == 1 ~ \"q1\",\n",
    "    quarter == 2 ~ \"q2\",\n",
    "    quarter == 3 ~ \"q3\",\n",
    "    quarter == 4 ~ \"q4\")) %>%\n",
    "    select(-quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see complete_df\n",
    "head(complete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can use the `tidyverse`'s `pivot_wider()` function to \"widen\" our data frame to get our desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spread the wage indicator by the new_quarter\n",
    "complete_df %>% \n",
    "    pivot_wider(names_from = new_quarter, values_from = wage_ind) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pivoted table\n",
    "wage_by_q <- complete_df %>% \n",
    "    pivot_wider(names_from = new_quarter, values_from = wage_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to count the number of people per unique combination of employment by each quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns <- wage_by_q %>%\n",
    "            group_by(q1, q2, q3, q4) %>%\n",
    "            summarize(count=n_distinct(ssn)) %>%\n",
    "            arrange(desc(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do these counts make sense? While this table can be plenty telling, let's put the cherry on top of this analysis by visualizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to visualize this table using color to highlight \"employment\" and \"no employment\" in each quarter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better not to use `count` column as an index, as there could be duplicate values - we will add those counts to our heatmap later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save counts to use later in the heatmap - we cannot use the counts as index, as there could be duplicate values \n",
    "counts <- patterns$count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add index with unique sequential numbers and remove the `count` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns$Pattern <- seq.int(nrow(patterns))\n",
    "patterns$count <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to convert this table from wide to long format - we can use `pivot_longer` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_long <- pivot_longer(patterns, names_to = 'Quarter', values_to = 'Status', -c(Pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(patterns_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create the visualization using `geom_tile` in `ggplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the plot\n",
    "\n",
    "levels = ordered(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16))  # specify in which order to add the rows from our wide table (called \"patterns\") \n",
    "                                                             # we want to preserve the same ordering of rows as they are sorted in the table from highest to lowest\n",
    "\n",
    "ggplot(data = patterns_long, aes(x = Quarter, y = ordered(Pattern, levels=rev(levels)))) +    # sort y-axis according to levels specified above\n",
    "geom_tile(aes(fill = Status), colour = 'black') +                                            # fill the table with value from Status column, create black contouring\n",
    "scale_fill_brewer(palette = \"Set1\") +                                                        # specify a color palette\n",
    "theme(text=element_text(size=14,face=\"bold\")) +                                                          # specify font size\n",
    "scale_x_discrete(position = 'top') +                                                         # include x-axis labels on top of the plot\n",
    "ylab('Employment - Individual Counts') +                                                     # add y-axis label\n",
    "ggtitle('2016Q4 Cohort: Employment Patterns by Quarters') +                                                 # add title for the plot\n",
    "labs(caption = 'Source: Indiana TANF, UI Wage data') +                                       # add data sourcing caption\n",
    "theme(plot.caption = element_text(hjust=0)) +                                                # move the data sourcing caption to the left corner of the graph\n",
    "scale_y_discrete(labels=rev(counts))  # rename the y-axis ticks to correspond to the counts from the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Side note**: what if we didn't filter our cohort to only adults? How would our employment patterns look like? \n",
    "> Let's recreate the above code using our dataframe with the full cohort, `df_2016`, including children:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join df_2016 with the df_2016_wages\n",
    "total_df <- df_2016 %>%\n",
    "    left_join(df_2016_wages, c(\"ssn\", \"tanf_spell_months\", \"tanf_total_months\", \"county\"))\n",
    "    \n",
    "# aggregate by quarter\n",
    "agg_df <- total_df %>%\n",
    "    group_by(ssn, quarter) %>%\n",
    "    summarize(wages = sum(wages)) %>%\n",
    "    ungroup()\n",
    "\n",
    "# set all where quarter is na equal to 1 so complete uses 1,2,3,4 as the options for quarter\n",
    "agg_df$quarter[is.na(agg_df$wages)] =1\n",
    "\n",
    "# need to complete df_2016_wages and fill out nas for all four quarters someone doesn't exist\n",
    "complete_df <- agg_df %>%\n",
    "    complete(ssn, quarter, fill=list(wages=0))\n",
    "\n",
    "# add new indicator column for if wages are greater than 0\n",
    "# then also get rid of the actual wages\n",
    "complete_df <- complete_df %>%\n",
    "    mutate(wage_ind = ifelse(wages == 0, \"no\", \"yes\")) %>%\n",
    "    select(-wages)\n",
    "\n",
    "# now need to expand so that each quarter is a row \n",
    "# but first, need to expand a character/factor, not a numerical column\n",
    "complete_df <- complete_df %>%\n",
    "    mutate(new_quarter = case_when(\n",
    "    quarter == 1 ~ \"q1\",\n",
    "    quarter == 2 ~ \"q2\",\n",
    "    quarter == 3 ~ \"q3\",\n",
    "    quarter == 4 ~ \"q4\")) %>%\n",
    "    select(-quarter)\n",
    "\n",
    "# save pivoted table\n",
    "wage_by_q <- complete_df %>% \n",
    "    pivot_wider(names_from = new_quarter, values_from = wage_ind)\n",
    "\n",
    "patterns <- wage_by_q %>%\n",
    "            group_by(q1, q2, q3, q4) %>%\n",
    "            summarize(count=n_distinct(ssn)) %>%\n",
    "            arrange(desc(count))\n",
    "\n",
    "# Save counts to use later in the heatmap - we cannot use the counts as index, as there could be duplicate values \n",
    "counts <- patterns$count\n",
    "\n",
    "patterns$Pattern <- seq.int(nrow(patterns))\n",
    "patterns$count <- NULL\n",
    "\n",
    "patterns_long <- pivot_longer(patterns, names_to = 'Quarter', values_to = 'Status', -c(Pattern))\n",
    "\n",
    "# Plot\n",
    "levels = ordered(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16))  # specify in which order to add the rows from our wide table (called \"patterns\") \n",
    "                                                             # we want to preserve the same ordering of rows as they are sorted in the table from highest to lowest\n",
    "\n",
    "ggplot(data = patterns_long, aes(x = Quarter, y = ordered(Pattern, levels=rev(levels)))) +    # sort y-axis according to levels specified above\n",
    "geom_tile(aes(fill = Status), colour = 'black') +                                            # fill the table with value from Status column, create black contouring\n",
    "scale_fill_brewer(palette = \"Set1\") +                                                        # specify a color palette\n",
    "theme(text=element_text(size=14,face=\"bold\")) +                                                          # specify font size\n",
    "scale_x_discrete(position = 'top') +                                                         # include x-axis labels on top of the plot\n",
    "ylab('Employment - Individual Counts') +                                                     # add y-axis label\n",
    "ggtitle('2016Q4 Cohort: Employment Patterns by Quarters') +                                                 # add title for the plot\n",
    "labs(caption = 'Source: Indiana TANF, UI Wage data') +                                       # add data sourcing caption\n",
    "theme(plot.caption = element_text(hjust=0)) +                                                # move the data sourcing caption to the left corner of the graph\n",
    "scale_y_discrete(labels=rev(counts))  # rename the y-axis ticks to correspond to the counts from the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Do you notice the difference in the counts? The highest count of those who are not employed now also includes children under 18 years old from the cohort. It would be more accurate to filter our cohort table by only adults, like we did above. It's a good example of how we should think through our data and what we would like to show in our visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 6: Recreate for 2009Q1 </h3></font> \n",
    "\n",
    "Recreate this heatmap for the 2009Q1 cohort. Use a filtered cohort only with adults (and you can also try visualizing the full cohort (including children), to see the difference in the counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "adrf_r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
